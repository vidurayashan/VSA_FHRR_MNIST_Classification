{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c03ef24-de96-4082-93c6-e0872dc8e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scienceplots\n",
    "import matplotlib as mpl\n",
    "from copy import deepcopy\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0d6a98-a423-4c4b-8526-3b7c5d094596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.python.lib_FHRR_Loihi as lib\n",
    "import lib.python.utility as util\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg\n",
    "from lava.magma.core.run_conditions import RunSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3dbf82-dabe-4823-9f3d-299c499e0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_box_plots(data_sets, x_title=\"X Values\", y_title=\"Y Values\", title=\"\", show_box_plots=True, label_prefix=\"\", y_limits=None, x_limits=None, figsize=(10, 6), show_outliers=False):\n",
    "    \"\"\"\n",
    "    Plots multiple sets of customized black and white box plots for each x value with multiple y values,\n",
    "    indicates outliers, and adds a line graph connecting the means of y values for each dataset.\n",
    "\n",
    "    Parameters:\n",
    "    data_sets (list of dicts): List of dictionaries, each containing 'x_values', 'y_values', and 'title' keys.\n",
    "                               Each dictionary represents a dataset.\n",
    "    x_title (str): Label for the x-axis.\n",
    "    y_title (str): Label for the y-axis.\n",
    "    title (str): Overall title of the plot.\n",
    "    show_box_plots (bool): If True, display box plots. If False, only plot the means.\n",
    "    y_limits (tuple): Optional parameter to set the y-axis limits. Should be a tuple (y_min, y_max).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.00, 7.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "    colors = ['black', 'blue', 'green', 'red', 'purple', 'orange']  # Add more colors as needed\n",
    "\n",
    "    for idx, data_set in enumerate(data_sets):\n",
    "        x_values = data_set['x_values']\n",
    "        y_values = data_set['y_values']\n",
    "        dataset_title = data_set.get('title', f'Dataset {idx + 1}')\n",
    "        color = colors[idx % len(colors)]\n",
    "        \n",
    "        if show_box_plots:\n",
    "            # Create the box plot\n",
    "            boxplot = ax.boxplot(y_values, positions=x_values, patch_artist=False, showmeans=True, meanline=True,\n",
    "                                 showfliers=show_outliers,\n",
    "                                 flierprops=dict(marker='x', color=color, markersize=5), boxprops=dict(color=color),\n",
    "                                 whiskerprops=dict(color=color), capprops=dict(color=color), medianprops=dict(color=color))\n",
    "        \n",
    "        # Calculate means of y values\n",
    "        means = [np.mean(y) for y in y_values]\n",
    "        \n",
    "        # Plot the line graph connecting the means\n",
    "        label_txt = label_prefix + f' {dataset_title}'\n",
    "        ax.plot(x_values, means, color=color, linestyle='-', marker='o', markerfacecolor='none', label=label_txt)\n",
    "\n",
    "    # Set the x-axis labels\n",
    "    ax.set_xticks(x_values)\n",
    "    ax.set_xticklabels([str(x) for x in x_values])\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(x_title)\n",
    "    ax.set_ylabel(y_title)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Set y-axis limits if provided\n",
    "    if y_limits is not None:\n",
    "        ax.set_ylim(y_limits)\n",
    "\n",
    "    if x_limits is not None:\n",
    "        ax.set_xlim(x_limits)\n",
    "\n",
    "    # Show the legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fba66e-a2d1-4b8e-b3d9-a25d10b03b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "def rate_encode(values, duration):\n",
    "    # Normalize values to [0, 1] range\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    normalized_values = (values - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Generate Poisson spike trains\n",
    "    spike_trains = np.random.binomial(1, normalized_values, (duration, len(values)))\n",
    "    return spike_trains, min_val, max_val\n",
    "\n",
    "# Decoding\n",
    "def rate_decode(spike_trains, duration, min_val, max_val):\n",
    "    # Count spikes and average over duration\n",
    "    spike_counts = np.sum(spike_trains, axis=0)\n",
    "    decoded_values = spike_counts / duration\n",
    "\n",
    "    # Denormalize values back to original range\n",
    "    original_values = decoded_values * (max_val - min_val) + min_val\n",
    "    return original_values\n",
    "\n",
    "def rate_decode_get_activity(spike_trains, duration, min_val, max_val):\n",
    "    spike_counts = np.sum(np.sum(spike_trains, axis=0))\n",
    "    return spike_counts\n",
    "\n",
    "# Encoding\n",
    "def latency_encode(values, duration):\n",
    "    # Normalize values to [0, 1] range\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    normalized_values = (values - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Generate spike trains based on latency\n",
    "    spike_trains = np.zeros((duration, len(values)))\n",
    "    for i, value in enumerate(normalized_values):\n",
    "        spike_time = int((1 - value) * (duration - 1))\n",
    "        spike_trains[spike_time, i] = 1\n",
    "    return spike_trains, min_val, max_val\n",
    "\n",
    "# Decoding\n",
    "def latency_decode(spike_trains, duration, min_val, max_val):\n",
    "    # Find the first spike time for each neuron\n",
    "    first_spike_times = np.argmax(spike_trains, axis=0)\n",
    "    \n",
    "    # Normalize back to [0, 1] range\n",
    "    normalized_values = 1 - (first_spike_times / (duration - 1))\n",
    "    \n",
    "    # Denormalize values back to original range\n",
    "    original_values = normalized_values * (max_val - min_val) + min_val\n",
    "    return original_values\n",
    "\n",
    "def preprocess_latency_encode_vec_TTFS(vec, v_th, sim_time):\n",
    "    # [f(x) if x is not None else '' for x in xs]\n",
    "    # vec = np.array([v_th * 4  if (2 * math.pi * v_th) / (sim_time * (elem)) > v_th else elem for elem in vec  ])\n",
    "    return v_th * (2* math.pi) / (vec * sim_time)\n",
    "\n",
    "def preprocess_latency_decode_vec_TTFS(vec, v_th, sim_time):\n",
    "    # [f(x) if x is not None else '' for x in xs]\n",
    "    # vec = np.array([v_th * 4  if (2 * math.pi * v_th) / (sim_time * (elem)) > v_th else elem for elem in vec  ])\n",
    "    return (v_th * 2*math.pi) / (sim_time * vec)\n",
    "    \n",
    "\n",
    "def preprocess_latency_encode_vec_Phase(vec, v_th, sim_time):\n",
    "    # [f(x) if x is not None else '' for x in xs]\n",
    "    # vec = np.array([v_th * 4  if (2 * math.pi * v_th) / (sim_time * (elem)) > v_th else elem for elem in vec  ])\n",
    "    return v_th * (vec) / ((2* math.pi) * sim_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f862b6d-3331-43d3-b783-393c42d41497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Values:\n",
      " [ 9.894  0.417  0.885  0.3   12.   ]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "values = np.array([10, 0.5, 0.81, 0.3, 12])  # Example d-dimensional array\n",
    "duration = 100\n",
    "\n",
    "# Encode\n",
    "spike_trains, min_val, max_val = rate_encode(values, duration)\n",
    "# print(\"Spike Trains:\\n\", spike_trains)\n",
    "\n",
    "# Decode\n",
    "decoded_values = rate_decode(spike_trains, duration, min_val, max_val)\n",
    "print(\"Decoded Values:\\n\", decoded_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd682a0b-a7bc-4f3d-a151-45f3bcc35562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_decode_get_activity(spike_trains, duration, min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590da54-c840-443d-a32c-2f2593f4199d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773948ec-d708-4f42-9516-69d3b37803f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
